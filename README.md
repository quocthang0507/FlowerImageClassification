# FlowerImageClassification

| T√™n kh√≥a lu·∫≠n | Lo·∫°i kh√≥a lu·∫≠n | Gi·∫£ng vi√™n h∆∞·ªõng d·∫´n | Sinh vi√™n th·ª±c hi·ªán | L·ªõp |
| --- | --- | --- | --- | --- |
| X√¢y d·ª±ng ·ª©ng d·ª•ng nh·∫≠n di·ªán lo√†i hoa s·ª≠ d·ª•ng th∆∞ vi·ªán ML.NET | Kho√° lu·∫≠n t·ªët nghi·ªáp k·ªπ s∆∞ C√¥ng ngh·ªá Th√¥ng tin | TS. Tr·∫ßn Ng√¥ Nh∆∞ Kh√°nh | 1610207, La Qu·ªëc Th·∫Øng | CTK40 |

*This solution is based on [DeepLearning_ImageClassification_Training](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ImageClassification_Training).*

Hope you like it! üòçüòçüòç Please don't miss the following information.

## B·∫£ng th√¥ng tin t√≥m t·∫Øt
| ML.NET version | API type | Status | App Type | Data type | Scenario | ML Task | Algorithms |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Microsoft.ML 1.5.2 | Dynamic API | Up-to-date | Console App, Web App (ASP.NET MVC) and Library in .NET Core | Image files | Image classification, Multiclass classification | Image classification with TensorFlow model retrain based on transfer learning  | DNN architectures: ResNet, InceptionV3, MobileNet |

## V·∫•n ƒë·ªÅ
Ph√¢n lo·∫°i h√¨nh ·∫£nh l√† m·ªôt b√†i to√°n th∆∞·ªùng th·∫•y trong lƒ©nh v·ª±c *H·ªçc S√¢u*. D∆∞·ªõi ƒë√¢y tr√¨nh b√†y c√°ch t·∫°o m·ªôt m√¥ h√¨nh ph√¢n lo·∫°i h√¨nh ·∫£nh tu·ª≥ bi·∫øn d·ª±a tr√™n c√°ch ti·∫øp c·∫≠n *chuy·ªÉn giao h·ªçc t·∫≠p*.

![](docs/image-classifier-scenario.png)
*K·ªãch b·∫£n ph√¢n lo·∫°i h√¨nh ·∫£nh, s·ª≠ d·ª•ng th∆∞ vi·ªán ML.NET x√¢y d·ª±ng m√¥ h√¨nh h·ªçc s√¢u tu·ª≥ bi·∫øn*

## T·∫≠p d·ªØ li·ªáu (Dataset/Imageset)
B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng nhi·ªÅu t·∫≠p h√¨nh ·∫£nh hoa kh√°c nhau, ch·∫≥ng h·∫°n t·∫≠p h√¨nh ·∫£nh n·ªïi ti·∫øng Oxford Flower Dataset c·ªßa Maria-Elena Nilsback v√† Andrew Zisserman
:
* [17 category dataset](https://www.robots.ox.ac.uk/~vgg/data/flowers/17/index.html): T·∫≠p h√¨nh ·∫£nh n√†y c√≥ 17 lo√†i hoa v·ªõi 80 h√¨nh ·∫£nh c·ªßa m·ªói lo√†i, l√† nh·ªØng lo√†i hoa ph·ªï bi·∫øn ·ªü V∆∞∆°ng qu·ªëc Anh.
![](docs/17categories.jpg)
* [102 category dataset](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html): T·∫≠p h√¨nh ·∫£nh n√†y c√≥ 102 lo√†i hoa v·ªõi t·ª´ 40 - 258 h√¨nh ·∫£nh c·ªßa m·ªói lo√†i, l√† nh·ªØng lo√†i hoa ph·ªï bi·∫øn ·ªü V∆∞∆°ng qu·ªëc Anh.
![](docs/102categories.jpg)

*2 t·∫≠p h√¨nh ·∫£nh tr√™n ch·ª©a c√°c ·∫£nh c√≥ nhi·ªÅu bi·∫øn th·ªÉ (·∫£nh s√°ng, t·ª∑ l·ªá, h√¨nh d√°ng) n√™n nhi·ªÅu ·∫£nh trong ƒë√≥ tr√¥ng kh√°c bi·ªát v·ªõi c√°c h√¨nh c√≤n l·∫°i.*

ƒê·ªÉ s·ª≠ d·ª•ng trong d·ª± √°n n√†y, b·∫°n c·∫ßn ph·∫£i ƒë∆∞a c√°c h√¨nh ·∫£nh v√†o ƒë√∫ng th∆∞ m·ª•c v·ªõi t√™n th∆∞ m·ª•c nh∆∞ l√† t√™n l·ªõp (Names as labels). T√¥i ƒë√£ s·∫Øp x·∫øp ch√∫ng, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng t·ª´ li√™n k·∫øt [n√†y](https://github.com/quocthang0507/ImageClassificationExample/tree/master/jpg) (cho t·∫≠p 17 category) ho·∫∑c t·ª´ li√™n k·∫øt [n√†y](https://github.com/quocthang0507/102-Category-Flower/tree/master/jpg) (cho t·∫≠p 102 category).

Trong ƒë·ªÅ t√†i n√†y, t√¥i s·ª≠ d·ª•ng t·∫≠p h√¨nh ·∫£nh c√≥ 5 lo√†i hoa kh√°c nhau l·∫•y t·ª´ [https://www.kaggle.com/alxmamaev/flowers-recognition](https://www.kaggle.com/alxmamaev/flowers-recognition).
![](docs/5categories.jpg)

Tensoflow c≈©ng cung c·∫•p m·ªôt t·∫≠p h√¨nh ·∫£nh, b·∫°n c√≥ th·ªÉ t·∫£i t·ª´ li√™n k·∫øt [n√†y](http://download.tensorflow.org/example_images/flower_photos.tgz).

> *Gi·∫•y ph√©p t·∫≠p h√¨nh ·∫£nh*
>
> All images in this archive are licensed under the Creative Commons By-Attribution License, available at:
https://creativecommons.org/licenses/by/2.0/
>
> Th√¥ng tin ƒë·∫ßy ƒë·ªß gi·∫•y ph√©p ƒë∆∞·ª£c cung c·∫•p trong t·∫≠p tin LICENSE.txt trong t·∫≠p tin n√©n .zip t·∫£i v·ªÅ.
> 
> All the images are from [Flickr](https://www.flickr.com/)
>
> This imageset is used only for educational and evaluational purposes, not for commercial purposes.

## ML Task - Ph√¢n lo·∫°i h√¨nh ·∫£nh

ƒê·ªÉ gi·∫£i quy·∫øt b√†i to√°n n√†y, ƒë·∫ßu ti√™n s·∫Ω x√¢y d·ª±ng m√¥ h√¨nh H·ªçc M√°y. Sau ƒë√≥, ch√∫ng ta hu·∫•n luy·ªáN m√¥ h√¨nh tr√™n d·ªØ li·ªáu s·∫µn c√≥, ƒë√°nh gi√° k·∫øt qu·∫£ v√† cu·ªëi c√πng l√† s·ª≠ d·ª•ng m√¥ h√¨nh x√¢y d·ª±ng ƒë∆∞·ª£c ƒë·ªÉ ph√¢n lo·∫°i c√°c h√¨nh ·∫£nh m·ªõi. D∆∞·ªõi ƒë√¢y tr√¨nh b√†y c√°c b∆∞·ªõc theo tr√¨nh t·ª±, c√°c ƒëo·∫°n m√£ th·∫≠t c√≥ th·ªÉ kh√°c ƒë√¥i ch√∫t v·ªõi c√°c ƒëo·∫°n m√£ m·∫´u. D·ª± √°n c√≥ t√™n l√† `FlowerImageClassification.Shared`.

![](docs/modelpipeline.png)

### 1. C·∫•u h√¨nh d·ª± √°n ƒë·ªÉ s·ª≠ d·ª•ng GPU ho·∫∑c CPU

B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng s·ª©c m·∫°nh s·∫µn c√≥ c·ªßa m√°y t√≠nh ƒë·ªÉ vi·ªác ƒë√†o t·∫°o s·ª≠ d·ª•ng CPU ho·∫∑c GPU. M·∫∑c ƒë·ªãnh, d·ª± √°n n√†y s·ª≠ d·ª•ng CPU, v√¨ y√™u c·∫ßu GPU h∆°i ch√∫t kh√≥ khƒÉn do b·∫°n ph·∫£i c√≥ m·ªôt card m√†n h√¨nh t∆∞∆°ng th√≠ch (ch·∫≥ng h·∫°n NVIDIA GPU graphics cards).

#### S·ª≠ d·ª•ng CPU

B·∫°n c·∫ßn tham chi·∫øu ƒë·∫øn th∆∞ vi·ªán: `SciSharp.TensorFlow.Redist`

![](docs/cpu.png)

#### S·ª≠ d·ª•ng GPU

B·∫°n c·∫ßn tham chi·∫øu ƒë·∫øn th∆∞ vi·ªán: `SciSharp.TensorFlow.Redist-Windows-GPU` ho·∫∑c `SciSharp.TensorFlow.Redist-Linux-GPU`

![](docs/gpu.png)

### 2. X√¢y d·ª±ng m√¥ h√¨nh

X√¢y d·ª±ng m√¥ h√¨nh v·ªõi c√°c b∆∞·ªõc sau:
* T·∫£i h√¨nh ·∫£nh v√†o m·ªôt IDataView
* S·ª≠ d·ª•ng ImageClassification Estimator (API c·∫•p cao) ƒë·ªÉ ph√¢n lo·∫°i h√¨nh ·∫£nh.

ƒê·ªãnh nghƒ©a l∆∞·ª£c ƒë·ªì d·ªØ li·ªáu trong m·ªôt l·ªõp.

```csharp
public class ImageData
{
    public ImageData(string imagePath, string label)
    {
        ImagePath = imagePath;
        Label = label;
    }

    public readonly string ImagePath;
    public readonly string Label;
}
```

B·ªüi v√¨ API s·ª≠ d·ª•ng h√¨nh ·∫£nh trong b·ªô nh·ªõ, n√™n ta c·∫ßn ƒë·ªãnh nghƒ©a m·ªôt l·ªõp ch·ª©a c√°c bits `byte[] Image` c·ªßa h√¨nh ·∫£nh v√†o ƒë√≥.

```csharp
public class InMemoryImageData
{
    public InMemoryImageData(byte[] image, string label, string imageFileName)
    {
        Image = image;
        Label = label;
        ImageFileName = imageFileName;
    }

    public readonly byte[] Image;
    public readonly string Label;
    public readonly string ImageFileName;
}
```

ƒê∆∞a th√¥ng tin h√¨nh ·∫£nh b·∫±ng LoadImagesFromDirectory() and LoadFromEnumerable().

```csharp
// 1. Download the image set and unzip
string finalImagesFolderName = DownloadImageSet(imagesDownloadFolderPath);
string fullImagesetFolderPath = Path.Combine(imagesDownloadFolderPath, finalImagesFolderName);

var mlContext = new MLContext(seed: 1);

// 2. Load the initial full image-set into an IDataView and shuffle so it'll be better balanced
IEnumerable<ImageData> images = LoadImagesFromDirectory(folder: fullImagesetFolderPath, useFolderNameAsLabel: true);
IDataView fullImagesDataset = mlContext.Data.LoadFromEnumerable(images);
IDataView shuffledFullImageFilePathsDataset = mlContext.Data.ShuffleRows(fullImagesDataset);
```

M·ªôt khi h√¨nh ·∫£nh ƒë∆∞·ª£c t·∫£i v√†o IDataView, c√°c d√≤ng s·∫Ω ƒë∆∞·ª£c x√°o tr·ªôn v√¨ v·∫≠y t·∫≠p d·ªØ li·ªáu tr·ªü n√™n *balance* h∆°n tr∆∞·ªõc khi chia th√†nh c√°c t·∫≠p ƒë√†o t·∫°o v√† t·∫≠p ki·ªÉm tra.

B√¢y gi·ªù l√† b∆∞·ªõc r·∫•t quan tr·ªçng. B·ªüi v√¨ m√¥ h√¨nh ML l√†m vi·ªác v·ªõi h√¨nh ·∫£nh trong b·ªô nh·ªõ, do ƒë√≥ ch√∫ng ta c·∫ßn t·∫£i h√¨nh ·∫£nh v√†o t·∫≠p d·ªØ li·ªáu v√† chuy·ªÉn ƒë·ªïi, ƒë∆∞a c√°c th√¥ng tin c·∫ßn thi·∫øt v√†o IDataView b·∫±ng c√°ch g·ªçi fit() v√† transform().

```csharp
// 3. Load Images with in-memory type within the IDataView and Transform Labels to Keys (Categorical)
IDataView shuffledFullImagesDataset = mlContext.Transforms.Conversion.
        MapValueToKey(outputColumnName: "LabelAsKey", inputColumnName: "Label", keyOrdinality: KeyOrdinality.ByValue)
    .Append(mlContext.Transforms.LoadRawImageBytes(
                                    outputColumnName: "Image",
                                    imageFolder: fullImagesetFolderPath,
                                    inputColumnName: "ImagePath"))
    .Fit(shuffledFullImageFilePathsDataset)
    .Transform(shuffledFullImageFilePathsDataset);
```

Ch√∫ng ta ƒë√£ chuy·ªÉn ƒë·ªïi c√°c nh√£n th√†nh kho√° (labels to keys). B√¢y gi·ªù s·∫Ω chia t·∫≠p d·ªØ li·ªáu th√†nh 2 ph·∫ßn: t·∫≠p ƒë√†o t·∫°o (80%) v√† t·∫≠p ki·ªÉm tra (20%).

```csharp
// 4. Split the data 80:20 into train and test sets, train and evaluate.
var trainTestData = mlContext.Data.TrainTestSplit(shuffledFullImagesDataset, testFraction: 0.2);
IDataView trainDataView = trainTestData.TrainSet;
IDataView testDataView = trainTestData.TestSet;
```

Ti·∫øp theo l√† ƒë·ªãnh nghƒ©a m·ªôt pipeline - ƒë√†o t·∫°o m·ªôt m√¥ h√¨nh Tensorflow d·ª±a tr√™n chuy·ªÉn giao h·ªçc t·∫≠p t·ª´ m·ªôt ki·∫øn tr√∫c m·∫∑c ƒë·ªãnh (pre-trained model) l√† *Resnet V2 500*.

```csharp
// 5. Define the model's training pipeline using DNN default values
//
var pipeline = mlContext.MulticlassClassification.Trainers
        .ImageClassification(featureColumnName: "Image",
                                labelColumnName: "LabelAsKey",
                                validationSet: testDataView)
    .Append(mlContext.Transforms.Conversion.MapKeyToValue(outputColumnName: "PredictedLabel",
                                                          inputColumnName: "PredictedLabel"));
```

`mlContext.MulticlassClassification.Trainers.ImageClassification` l√† m·ªôt API c·∫•p cao cho ph√©p ch√∫ng ta s·ª≠ d·ª•ng h√†m n√†y ƒë·ªÉ ph√¢n lo·∫°i h√¨nh ·∫£nh. Ch√∫ng ta ch·ªâ c·∫ßn ƒë∆∞a v√†o m·ªôt c·ªôt h√¨nh ·∫£nh, c·ªôt nh√£n v√† m·ªôt t·∫≠p d·ªØ li·ªáu ki·ªÉm tra m√† th√¥i.

B√™n d∆∞·ªõi m√¥ h√¨nh `mlContext.MulticlassClassification.Trainers.ImageClassification`n√†y l√† d·ª±a tr√™n m·ªôt *Native TensorFlow DNN transfer learning*.

Th·∫≠t ƒë∆°n gi·∫£n ph·∫£i kh√¥ng, b·∫°n kh√¥ng c·∫ßn ph·∫£i ch·ªânh l·∫°i k√≠ch th∆∞·ªõc, bi·∫øn ƒë·ªïi h√¨nh ·∫£nh, chu·∫©n ho√°,... Ch·ªâ c·∫ßn s·ª≠ d·ª•ng ki·∫øn tr√∫c DNN, framework s·∫Ω l√†m h·∫øt cho c√°c b·∫°n!!!

#### S·ª≠ d·ª•ng hyper-parameters n√¢ng cao trong b∆∞·ªõc 5

C√≥ nhi·ªÅu ki·∫øn tr√∫c DNN kh√°c nhau, b√™n c·∫°nh **Resnet V2 500** th√¨ c√≥ **[Inception v3](https://cloud.google.com/tpu/docs/inception-v3-advanced)** v√† **[Resnet v2101](https://medium.com/@bakiiii/microsoft-presents-deep-residual-networks-d0ebd3fe5887)**,... ƒê·ªìng th·ªùi ta c√≥ th·ªÉ thay ƒë·ªïi c√°c hyper-parameters nh∆∞ epochs, batchSize, learningRate. Nh√¨n v√†o d∆∞·ªõi ƒë√¢y s·∫Ω hi·ªÉu.

```csharp 
// 5.1 (OPTIONAL) Define the model's training pipeline by using explicit hyper-parameters

var options = new ImageClassificationTrainer.Options()
{
    FeatureColumnName = "Image",
    LabelColumnName = "LabelAsKey",
    // Just by changing/selecting InceptionV3/MobilenetV2/ResnetV250  
    // you can try a different DNN architecture (TensorFlow pre-trained model). 
    Arch = ImageClassificationTrainer.Architecture.MobilenetV2,
    Epoch = 50,       //100
    BatchSize = 10,
    LearningRate = 0.01f,
    MetricsCallback = (metrics) => Console.WriteLine(metrics),
    ValidationSet = testDataView
};

var pipeline = mlContext.MulticlassClassification.Trainers.ImageClassification(options)
        .Append(mlContext.Transforms.Conversion.MapKeyToValue(
            outputColumnName: "PredictedLabel",
            inputColumnName: "PredictedLabel"));
```

### 3. ƒê√†o t·∫°o m√¥ h√¨nh

G·ªçi h√†m `Fit` trong pipeline v√† ng·ªìi nh√¨n n√≥ ho·∫°t ƒë·ªông:

```csharp 
// 4. Train/create the ML model
ITransformer trainedModel = pipeline.Fit(trainDataView);
```

### 4. ƒê√°nh gi√° m√¥ h√¨nh

H√†m `Evaluate` c·∫ßn m·ªôt IDataView, tr∆∞·ªõc khi ƒë∆∞a `testDataset` v√†o, ch√∫ng ta s·∫Ω g·ªçi h√†m Transform().

```csharp
// 5. Get the quality metrics (accuracy, etc.)
IDataView predictionsDataView = trainedModel.Transform(testDataset);

var metrics = mlContext.MulticlassClassification.Evaluate(predictionsDataView, labelColumnName:"LabelAsKey", predictedLabelColumnName: "PredictedLabel");
ConsoleHelper.PrintMultiClassClassificationMetrics("TensorFlow DNN Transfer Learning", metrics);
```

Xong r·ªìi, l∆∞u m√¥ h√¨nh ƒë√†o t·∫°o ƒë∆∞·ª£c v√†o m√°y th√¥i:
```csharp
// Save the model to assets/outputs (You get ML.NET .zip model file and TensorFlow .pb model file)
mlContext.Model.Save(trainedModel, trainDataView.Schema, outputMlNetModelFilePath);
```

#### Ch·∫°y ch∆∞∆°ng tr√¨nh l√™n th√¥i

√Ä nh∆∞ng tr∆∞·ªõc h·∫øt, b·∫°n c·∫ßn ph·∫£i g√°n c√°c ƒë∆∞·ªùng d·∫´n v√†o c√°c bi·∫øn t∆∞∆°ng ·ª©ng nh√©. V√†o d·ª± √°n `FlowerImageClassification.Training`, trong t·∫≠p tin `program.cs`, b·∫°n nh√¨n th·∫•y th√¨ s·∫Ω bi·∫øt c·∫ßn ph·∫£i l√†m g√¨ r·ªìi ch·ª©.

### 5. S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√†o t·∫°o ƒë∆∞·ª£c v√†o c√°c d·ª± √°n kh√°c

Sao ch√©p m√¥ h√¨nh `.zip` v√†o m·ªôt n∆°i n√†o ƒë√≥, nh∆∞ trong ch∆∞∆°ng tr√¨nh c·ªßa t√¥i, t√¥i ƒë√£ ƒë·ªÉ ch√∫ng v√†o m·ªôt th∆∞ m·ª•c t√™n l√† `Assets`. Tuy nhi√™n, n·∫øu c√°c d·ª± √°n ch·∫°y t·ª´ Visual Studio th√¨ ok, nh∆∞ng n·∫øu b·∫°n Release ch∆∞∆°ng tr√¨nh v√† mang ƒëi n∆°i kh√°c, th√¨ c·∫©n th·∫≠n, v√¨ ƒë∆∞·ªùng d·∫´n l∆∞u trong ch∆∞∆°ng tr√¨nh c√≥ l·∫Ω s·∫Ω kh√¥ng kh·ªõp v·ªõi ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø.

```csharp
MLContext mlContext = new MLContext(seed: 1);
ITransformer loadedModel = mlContext.Model.Load(imageClassifierModelZipFilePath, out var modelInputSchema);
```

```csharp
var predictionEngine = mlContext.Model.CreatePredictionEngine<InMemoryImageData, ImagePrediction>(loadedModel);

//Predict the first image in the folder
IEnumerable<InMemoryImageData> imagesToPredict = LoadInMemoryImagesFromDirectory(
    imagesFolderPathForPredictions, false);

InMemoryImageData imageToPredict = new InMemoryImageData
{
    Image = imagesToPredict.First().Image,
    ImageFileName = imagesToPredict.First().ImageFileName
};

var prediction = predictionEngine.Predict(imageToPredict);

// Get the highest score and its index
float maxScore = prediction.Score.Max();

Console.WriteLine($"Image Filename : [{imageToPredict.ImageFileName}		$"Predicted Label : [{prediction.PredictedLabel}], " +
    $"Probability : [{maxScore}] ");
```

R·ªìi b√¢y gi·ªù, b·∫°n c√≥ th·ªÉ kh√°m ph√° r·ªìi ƒë√≥.

# TensorFlow DNN Transfer Learning background information

This sample app is retraining a TensorFlow model for image classification. As a user, you could think it is pretty similar to this other sample [Image classifier using the TensorFlow Estimator featurizer](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_TensorFlowEstimator). However, the internal implementation is very different under the covers. In that mentioned sample, it is using a 'model composition approach' where an initial TensorFlow model (i.e. InceptionV3 or ResNet) is only used to featurize the images and produce the binary information per image to be used by another ML.NET classifier trainer added on top (such as `LbfgsMaximumEntropy`). Therefore, even when that sample is using a TensorFlow model, you are training only with a ML.NET trainer, you don't retrain a new TensorFlow model but train an ML.NET model. That's why the output of that sample is only an ML.NET model (.zip file).

In contrast, this sample is natively retraining a new TensorFlow model based on a Transfer Learning approach but training a new TensorFlow model derived from the specified pre-trained model (Inception V3 or ResNet).

The important difference is that this approach is internally retraining with TensorFlow APIs and creating a new TensorFlow model (.pb). Then, the ML.NET .zip file model you use is just like a wrapper around the new retrained TensorFlow model. This is why you can also see a new .pb file generated after training:

![](docs/meta.pb.png)

In the screenshot below you can see how you can see that retrained TensorFlow model (`custom_retrained_model_based_on_InceptionV3.meta.pb`) in **Netron**, since it is a native TensorFlow model:

![](docs/netron.png)

**Benefits:** 

- **Train and inference using GPU:**
    When using this native DNN approach based on TensorFlow you can either use the CPU or GPU (if available) for a better performance (less time needed for training and scoring).

- **Reuse across multiple frameworks and platforms:**
    This ultimately means that since you natively trained a Tensorflow model, in addition to being able to run/consume that model with the ML.NET 'wrapper' model (.zip file), you could also take the .pb TensorFlow frozen model and run it on any other framework such as Python/Keras/TensorFlow, or a Java/Android app or any framework that supports TensorFlow.
- **Flexibility and performace:** Since ML.NET is internally retraining natively on Tensorflow layers, the ML.NET team will be able to optimize further and take multiple approaches like training on the last layer or training on multiple layers across the TensorFlow model and achive better quality levels.
